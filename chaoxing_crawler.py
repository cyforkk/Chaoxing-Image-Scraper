import requests
import re
import os
from urllib.parse import urljoin
import time


class ChaoxingImageCrawler:
    def __init__(self, cookies):
        self.session = requests.Session()
        self.session.cookies.update(cookies)
        self.headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36"
        }
        self.log_callback = None

    def log(self, message):
        if self.log_callback:
            self.log_callback(message)
        else:
            print(message)

    def get_course_content(self, url):
        try:
            response = self.session.get(url, headers=self.headers)
            response.encoding = "utf-8"
            return response.text
        except Exception as e:
            self.log(f"è·å–é¡µé¢å†…å®¹å¤±è´¥: {e}")
            return None

    def extract_images(self, html):
        images = []

        img_patterns = [
            r'<img[^>]+src="([^"]+)"',
            r"<img[^>]+src=\'([^\']+)\'",
            r'"url":"([^"]+\.jpg[^"]*)"',
            r'"url":"([^"]+\.png[^"]*)"',
            r'"orig":"([^"]+)"',
            r'background-image:\s*url\(["\']?([^)"\']+)["\']?\)',
            r'https?://[^"\'>\s]+ananas[^"\'>\s]+',
            r'https?://[^"\'>\s]+/sv-w8/[^"\'>\s]+',
            r'https://s[0-9]\.ananas\.chaoxing\.com[^\s"\'<>]+',
        ]

        for pattern in img_patterns:
            matches = re.findall(pattern, html)
            for match in matches:
                if match and not match.startswith("data:"):
                    if "/sv-w8/doc/" in match or "ananas.chaoxing.com" in match:
                        images.append(match)

        return list(set(images))

    def download_image(self, img_url, save_dir, course_name, chapter_name, index):
        try:
            if not img_url.startswith("http"):
                img_url = urljoin("https://mooc1.chaoxing.com/", img_url)

            ext = os.path.splitext(img_url.split("?")[0])[1] or ".png"
            filename = f"{course_name}-{chapter_name}-{index}{ext}"
            filename = re.sub(r'[<>:"/\\|?*]', "_", filename)

            filepath = os.path.join(save_dir, filename)

            response = self.session.get(img_url, headers=self.headers, timeout=10)
            if response.status_code == 200:
                with open(filepath, "wb") as f:
                    f.write(response.content)
                self.log(f"ä¸‹è½½æˆåŠŸ: {filename}")
                self.log(f"ä¿å­˜è·¯å¾„: {filepath}")
                return True
            else:
                self.log(f"ä¸‹è½½å¤±è´¥: {img_url} (çŠ¶æ€ç : {response.status_code})")
                return False
        except Exception as e:
            self.log(f"ä¸‹è½½å›¾ç‰‡å¤±è´¥: {img_url}, é”™è¯¯: {e}")
            return False

    def crawl_homework_images(self, course_url, save_dir="images"):
        """çˆ¬å–ä½œä¸šå›¾ç‰‡"""
        save_dir = os.path.abspath(save_dir)
        os.makedirs(save_dir, exist_ok=True)
        self.log(f"ä¿å­˜ç›®å½•: {save_dir}")

        self.log("æ­£åœ¨è·å–ä½œä¸šé¡µé¢...")
        
        try:
            response = self.session.get(course_url, headers=self.headers)
            response.encoding = "utf-8"
            html = response.text
            
            self.log(f"é¡µé¢å“åº”é•¿åº¦: {len(html)}")
            
            # æå–è¯¾ç¨‹å
            course_name_match = re.search(r'"coursename"\s*:\s*"([^"]+)"', html)
            course_name = course_name_match.group(1) if course_name_match else "è¯¾ç¨‹"
            self.log(f"è¯¾ç¨‹åç§°: {course_name}")
            
            # ä¼˜å…ˆä» mark_title æå–é¢˜ç›®åç§°
            title_match = re.search(r'<h2 class="mark_title"[^>]*>([^<]+)</h2>', html)
            if title_match:
                homework_name = title_match.group(1).strip()
            else:
                # å¦‚æœæ²¡æœ‰ï¼Œå°è¯•ä» knowledgename æå–
                knowledge_name_match = re.search(r'"knowledgename"\s*:\s*"([^"]+)"', html)
                homework_name = knowledge_name_match.group(1) if knowledge_name_match else "ä½œä¸š"
            self.log(f"é¢˜ç›®åç§°: {homework_name}")
            
            # æå–ä½œä¸šå›¾ç‰‡ï¼ˆä» stuAnswerContent åŒºåŸŸï¼‰
            self.log("æ­£åœ¨æŸ¥æ‰¾ä½œä¸šå›¾ç‰‡...")
            
            # åŒ¹é… stuAnswerContent åŒºåŸŸçš„å›¾ç‰‡
            answer_pattern = r'<dd class="textwrap stuAnswerContent[^"]*">(.*?)</dd>'
            answer_sections = re.findall(answer_pattern, html, re.DOTALL)
            
            images = []
            for section in answer_sections:
                # æå– data-original å±æ€§ï¼ˆåŸå›¾ï¼‰
                img_matches = re.findall(r'data-original="([^"]+)"', section)
                images.extend(img_matches)
                
                # å¦‚æœæ²¡æœ‰ data-originalï¼Œå°è¯•æå– src
                if not img_matches:
                    src_matches = re.findall(r'<img[^>]+src="([^"]+)"', section)
                    images.extend(src_matches)
            
            # å»é‡
            images = list(set(images))
            
            self.log(f"æ‰¾åˆ° {len(images)} å¼ å›¾ç‰‡")
            
            if not images:
                self.log("âš ï¸ æœªæ‰¾åˆ°å›¾ç‰‡")
                self.log("ğŸ’¡ æç¤ºï¼š")
                self.log("    - è¯·ç¡®è®¤è¯¥é¡µé¢æ˜¯ä½œä¸šç­”æ¡ˆé¡µé¢")
                self.log("    - è¯·ç¡®è®¤ä½œä¸šç­”æ¡ˆåŒºåŸŸåŒ…å«å›¾ç‰‡")
                self.log("    - å¦‚æœæ˜¯è¯¾ç¨‹ç« èŠ‚ï¼Œè¯·é€‰æ‹©â€œğŸ“š è¯¾ç¨‹å›¾ç‰‡â€æ¨¡å¼")
                return False
            
            success_count = 0
            for i, img_url in enumerate(images, 1):
                self.log(f"[{i}/{len(images)}] æ­£åœ¨ä¸‹è½½: {img_url[:70]}...")
                if self.download_image(img_url, save_dir, course_name, homework_name, i):
                    success_count += 1
                time.sleep(0.5)
            
            self.log(f"\nä¸‹è½½å®Œæˆ! æˆåŠŸä¸‹è½½ {success_count}/{len(images)} å¼ å›¾ç‰‡")
            
            if success_count > 0:
                self.log(f"âœ“ å›¾ç‰‡å·²ä¿å­˜åˆ°: {save_dir}")
            
            return success_count > 0
            
        except Exception as e:
            self.log(f"çˆ¬å–ä½œä¸šå›¾ç‰‡å¤±è´¥: {e}")
            return False

    def crawl_images(self, course_url, save_dir="images"):
        save_dir = os.path.abspath(save_dir)
        os.makedirs(save_dir, exist_ok=True)
        self.log(f"ä¿å­˜ç›®å½•: {save_dir}")

        self.log("æ­£åœ¨ä»URLæå–å‚æ•°...")
        chapter_id_match = re.search(r"chapterId=([^&]+)", course_url)
        if not chapter_id_match:
            self.log("âš ï¸ æ— æ³•ä»URLæå–chapterId")
            self.log("ğŸ’¡ æç¤ºï¼šè¯·ç¡®è®¤æ‚¨é€‰æ‹©äº†æ­£ç¡®çš„çˆ¬å–æ¨¡å¼ï¼š")
            self.log("    - è¯¾ç¨‹å›¾ç‰‡ï¼šéœ€è¦è¯¾ç¨‹ç« èŠ‚é“¾æ¥ï¼ˆåŒ…å«chapterIdå‚æ•°ï¼‰")
            self.log("    - ä½œä¸šå›¾ç‰‡ï¼šéœ€è¦ä½œä¸šé¡µé¢é“¾æ¥")
            return False

        chapter_id = chapter_id_match.group(1)
        course_id_match = re.search(r"courseId=([^&]+)", course_url)
        course_id = course_id_match.group(1) if course_id_match else "254411132"
        clazz_id_match = re.search(r"clazzid=([^&]+)", course_url)
        clazz_id = clazz_id_match.group(1) if clazz_id_match else "126771918"
        cpi_match = re.search(r"cpi=([^&]+)", course_url)
        cpi = cpi_match.group(1) if cpi_match else "355954326"

        self.log(f"è¯¾ç¨‹ID: {course_id}, ç« èŠ‚ID: {chapter_id}, ç­çº§ID: {clazz_id}")

        cards_url = f"https://mooc1.chaoxing.com/mooc-ans/knowledge/cards?clazzid={clazz_id}&courseid={course_id}&knowledgeid={chapter_id}&num=0&ut=s&cpi={cpi}&v=2025-0424-1038-3&mooc2=1&isMicroCourse=false&editorPreview=0"
        self.log(f"æ­£åœ¨è¯·æ±‚å¡ç‰‡API: {cards_url[:70]}...")

        response = self.session.get(cards_url, headers=self.headers)

        if response.status_code == 200:
            cards_html = response.text
            self.log(f"å¡ç‰‡APIå“åº”é•¿åº¦: {len(cards_html)}")

            course_name_match = re.search(r'"coursename"\s*:\s*"([^"]+)"', cards_html)
            course_name = course_name_match.group(1) if course_name_match else "è¯¾ç¨‹"
            self.log(f"è¯¾ç¨‹åç§°: {course_name}")

            knowledge_name_match = re.search(
                r'"knowledgename"\s*:\s*"([^"]+)"', cards_html
            )
            knowledge_name = (
                knowledge_name_match.group(1) if knowledge_name_match else "ç« èŠ‚"
            )
            self.log(f"ç« èŠ‚åç§°: {knowledge_name}")

            self.log("æ­£åœ¨æŸ¥æ‰¾PDFæ–‡æ¡£ä¿¡æ¯...")
            objectid_match = re.search(r'"objectid"\s*:\s*"([^"]+)"', cards_html)
            if not objectid_match:
                objectid_match = re.search(r'objectid=([^\s"\'>]+)', cards_html)

            if objectid_match:
                objectid = objectid_match.group(1)
                self.log(f"æ‰¾åˆ°objectid: {objectid}")

                self.log("æ­£åœ¨å°è¯•ç›´æ¥è¯·æ±‚é¢„è§ˆé¡µé¢...")
                ext_param = f"%7B%22_from_%22%3A%22254411132_126771918_305455632_834b328b9c76ad47c6ea0999c20c6ba0%22%7D"
                preview_url = f"https://pan-yz.chaoxing.com/preview/objectshowpreview.html?objectid={objectid}&puid=111690846&ext={ext_param}"
                self.log(f"æ­£åœ¨è¯·æ±‚: {preview_url[:90]}...")

                preview_response = self.session.get(preview_url, headers=self.headers)
                if preview_response.status_code == 200:
                    preview_html = preview_response.text
                    self.log(f"é¢„è§ˆé¡µé¢å“åº”é•¿åº¦: {len(preview_html)}")

                    images = self.extract_images(preview_html)
                else:
                    self.log(f"é¢„è§ˆé¡µé¢è¯·æ±‚å¤±è´¥: {preview_response.status_code}")
                    images = []
            else:
                self.log("æœªæ‰¾åˆ°objectid")
                images = []

            self.log(f"æ‰¾åˆ° {len(images)} å¼ å›¾ç‰‡")

            if not images:
                self.log("æœªæ‰¾åˆ°å›¾ç‰‡")
                return False

            success_count = 0
            for i, img_url in enumerate(images, 1):
                self.log(f"[{i}/{len(images)}] æ­£åœ¨ä¸‹è½½: {img_url[:70]}...")
                if self.download_image(
                    img_url, save_dir, course_name, knowledge_name, i
                ):
                    success_count += 1
                time.sleep(0.5)

            self.log(f"\nä¸‹è½½å®Œæˆ! æˆåŠŸä¸‹è½½ {success_count}/{len(images)} å¼ å›¾ç‰‡")

            if success_count > 0:
                self.log(f"âœ“ å›¾ç‰‡å·²ä¿å­˜åˆ°: {save_dir}")

            return success_count > 0
        else:
            self.log(f"è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
            return False


def main():
    url = "https://mooc1.chaoxing.com/mycourse/studentstudy?chapterId=1093036095&courseId=214977771&clazzid=127435593&cpi=355954326&enc=0ba34fdf47f5f9441f2a7eabe136ecc2&mooc2=1&hidetype=0&openc=2e12069d6d211aa4000f976a8068539a"

    cookies = {
        "fid": "1895",
        "fanyamoocs": "11401F839C536D9E",
        "_uid": "305455632",
        "_d": "1766664171071",
        "UID": "305455632",
        "vc3": "SyGPeDytY2u4hnf2N%2BGXyxMNd1EWQX29vAk7UHg%2BMNgdxBsj55JEonuPS50ioy6lKEdLmpkqSoIG6tBhJrBAtcm3Ct2ygl1s0YOcCRHFkclJJXJBpbv5SwiyAlH5F8uAX3MawKPkdw9nNCY6OPLfPDKlx8iuryXGPAnWq7GuXNY%3D68b401cb982961dd56b95d7b7ea1020a",
        "uf": "b2d2c93beefa90dc431ba9687b542d8649cb6fd4383e557cd3d29c38c74757bd59263422de87ea97f82c82ed84ba88a981a6c9ddee30899fd807a544f7930b6aed1e6c11a143bb563b0339d97cdac4baabdbe8f75da1a98fe5851b744f8aa02c9fb3947ed09a594cc1ce0b14d44f76133121ccd7dcbdac27bf0117e20ffcf8b2a7dfae10ab92c0acc83af620aa8ae3f770b5a05e402d2a6370184964ffe8c27cda1a2f067a584887f183e159dc5a6222b1f899d50c1c3fa3aa2ebad65cd196bb",
        "cx_p_token": "9773c7ed30997ae3c554799ed9044329",
        "p_auth_token": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1aWQiOiIzMDU0NTU2MzIiLCJsb2dpblRpbWUiOjE3NjY2NjQxNzEwNzIsImV4cCI6MTc2NzI2ODk3MX0.T8sz2LHao4_KVh-YpnTWbOtoUFKOjkEXY0wFogkm1Do",
        "xxtenc": "f47e3db297a57d609dfc03c59b6fd1e6",
        "DSSTASH_LOG": "C_38-UN_192-US_305455632-T_1766664171073",
        "thirdRegist": "0",
        "k8s": "1766664189.835.112.921552",
        "route": "0eb899bb9bb390391b050e8cb1d78cb4",
        "jrose": "6201E6DA46AFC0FD529F85F974A551B3.mooc-p4-1368682161-9bfgs",
        "_industry": "5",
        "255200491cpi": "355954326",
        "255200491ut": "s",
        "255200491t": "1766710774233",
        "255200491enc": "9d65c3faacb7a2b628d98fbe01aea7f9",
        "254411132cpi": "355954326",
        "254411132ut": "s",
        "254411132t": "1766710904758",
        "254411132enc": "4a4ba5fff37a329b8dcdfeb1bd07fe53",
    }

    crawler = ChaoxingImageCrawler(cookies)
    crawler.crawl_images(url)


if __name__ == "__main__":
    main()
